Use Spark and data lakes to build an ETL pipeline for a data lake hosted on S3. 

To complete the project, I will load data from S3, process the data into analytics tables using Spark, 
and load them back into S3. 

I'll deploy this Spark process on a cluster using AWS.
